# Implementation Recommendations: Improving streamz with pipz Patterns

**Author:** midgel (Technical Architecture)  
**Date:** 2025-08-24  
**Version:** 1.0  

---

## Executive Summary

Based on the comprehensive analysis, streamz needs significant improvements to reach production readiness. This document provides **specific, actionable recommendations** with implementation details, prioritized by impact and urgency.

**Critical finding:** streamz testing infrastructure is completely inadequate for production use. This must be addressed before any other improvements.

---

## Priority 1: Critical Testing Infrastructure (URGENT)

### 1.1 Mock Processor Framework

**Problem:** streamz has no mocking capabilities, making testing extremely difficult.

**Solution:** Implement comprehensive mock framework based on pipz patterns.

#### Implementation Blueprint:

**File:** `streamz/testing/mocks/mock_processor.go`
```go
package mocks

import (
    "context"
    "sync"
    "sync/atomic"
    "testing"
    "time"
)

// MockProcessor provides configurable mock for stream processors
type MockProcessor[In, Out any] struct {
    t                *testing.T
    name             string
    transformFunc    func(In) Out
    errorFunc        func(In) error
    delay            time.Duration
    callCount        int64
    callHistory      []MockCall[In]
    maxHistory       int
    mu               sync.RWMutex
}

type MockCall[In any] struct {
    Input     In
    Timestamp time.Time
    Context   context.Context
}

func NewMockProcessor[In, Out any](t *testing.T, name string) *MockProcessor[In, Out] {
    return &MockProcessor[In, Out]{
        t:          t,
        name:       name,
        maxHistory: 100,
    }
}

func (m *MockProcessor[In, Out]) WithTransform(fn func(In) Out) *MockProcessor[In, Out] {
    m.transformFunc = fn
    return m
}

func (m *MockProcessor[In, Out]) WithError(fn func(In) error) *MockProcessor[In, Out] {
    m.errorFunc = fn
    return m
}

func (m *MockProcessor[In, Out]) WithDelay(d time.Duration) *MockProcessor[In, Out] {
    m.delay = d
    return m
}

func (m *MockProcessor[In, Out]) Process(ctx context.Context, in <-chan In) <-chan Out {
    out := make(chan Out)
    
    go func() {
        defer close(out)
        
        for item := range in {
            atomic.AddInt64(&m.callCount, 1)
            
            // Record call
            m.recordCall(MockCall[In]{
                Input:     item,
                Timestamp: time.Now(),
                Context:   ctx,
            })
            
            // Apply delay if configured
            if m.delay > 0 {
                select {
                case <-time.After(m.delay):
                case <-ctx.Done():
                    return
                }
            }
            
            // Check for error
            if m.errorFunc != nil {
                if err := m.errorFunc(item); err != nil {
                    // Skip item on error (configurable behavior)
                    continue
                }
            }
            
            // Transform item
            var result Out
            if m.transformFunc != nil {
                result = m.transformFunc(item)
            } else {
                // Default: pass through if types match
                if any(item) != nil {
                    if converted, ok := any(item).(Out); ok {
                        result = converted
                    }
                }
            }
            
            select {
            case out <- result:
            case <-ctx.Done():
                return
            }
        }
    }()
    
    return out
}

func (m *MockProcessor[In, Out]) Name() string {
    return m.name
}

func (m *MockProcessor[In, Out]) CallCount() int {
    return int(atomic.LoadInt64(&m.callCount))
}

func (m *MockProcessor[In, Out]) CallHistory() []MockCall[In] {
    m.mu.RLock()
    defer m.mu.RUnlock()
    
    result := make([]MockCall[In], len(m.callHistory))
    copy(result, m.callHistory)
    return result
}

func (m *MockProcessor[In, Out]) recordCall(call MockCall[In]) {
    m.mu.Lock()
    defer m.mu.Unlock()
    
    m.callHistory = append(m.callHistory, call)
    if len(m.callHistory) > m.maxHistory {
        m.callHistory = m.callHistory[1:]
    }
}

// Assertion helpers
func AssertProcessed[In, Out any](t *testing.T, mock *MockProcessor[In, Out], expectedCalls int) {
    t.Helper()
    if actual := mock.CallCount(); actual != expectedCalls {
        t.Errorf("expected %d calls, got %d", expectedCalls, actual)
    }
}

func AssertProcessedWithin[In, Out any](t *testing.T, mock *MockProcessor[In, Out], min, max int) {
    t.Helper()
    actual := mock.CallCount()
    if actual < min || actual > max {
        t.Errorf("expected calls between %d and %d, got %d", min, max, actual)
    }
}
```

### 1.2 Chaos Engineering Framework

**Problem:** No chaos testing capabilities for reliability validation.

**Solution:** Implement chaos processor for fault injection testing.

#### Implementation Blueprint:

**File:** `streamz/testing/chaos/chaos_processor.go`
```go
package chaos

import (
    "context"
    "math/rand"
    "sync/atomic"
    "time"
    
    "github.com/zoobzio/streamz"
)

type ChaosProcessor[T any] struct {
    name         string
    wrapped      streamz.Processor[T, T]
    config       ChaosConfig
    rng          *rand.Rand
    stats        ChaosStats
}

type ChaosConfig struct {
    FailureRate  float64       // Probability of dropping items
    LatencyMin   time.Duration // Minimum added latency
    LatencyMax   time.Duration // Maximum added latency
    DuplicationRate float64    // Probability of duplicating items
    ReorderWindow   int        // Window for reordering items
    Seed         int64         // Random seed for reproducibility
}

type ChaosStats struct {
    TotalItems    int64
    DroppedItems  int64
    DelayedItems  int64
    DuplicatedItems int64
    ReorderedItems  int64
}

func NewChaosProcessor[T any](name string, wrapped streamz.Processor[T, T], config ChaosConfig) *ChaosProcessor[T] {
    seed := config.Seed
    if seed == 0 {
        seed = time.Now().UnixNano()
    }
    
    return &ChaosProcessor[T]{
        name:    name,
        wrapped: wrapped,
        config:  config,
        rng:     rand.New(rand.NewSource(seed)),
    }
}

func (c *ChaosProcessor[T]) Process(ctx context.Context, in <-chan T) <-chan T {
    // First pass through wrapped processor
    processed := c.wrapped.Process(ctx, in)
    
    // Apply chaos to output
    out := make(chan T)
    
    go func() {
        defer close(out)
        
        var reorderBuffer []T
        
        for item := range processed {
            atomic.AddInt64(&c.stats.TotalItems, 1)
            
            // Apply latency chaos
            if c.config.LatencyMax > c.config.LatencyMin {
                latencyRange := c.config.LatencyMax - c.config.LatencyMin
                latency := c.config.LatencyMin + time.Duration(c.rng.Int63n(int64(latencyRange)))
                
                if latency > 0 {
                    atomic.AddInt64(&c.stats.DelayedItems, 1)
                    select {
                    case <-time.After(latency):
                    case <-ctx.Done():
                        return
                    }
                }
            }
            
            // Drop items (failure simulation)
            if c.rng.Float64() < c.config.FailureRate {
                atomic.AddInt64(&c.stats.DroppedItems, 1)
                continue
            }
            
            // Duplicate items
            if c.rng.Float64() < c.config.DuplicationRate {
                atomic.AddInt64(&c.stats.DuplicatedItems, 1)
                select {
                case out <- item:
                case <-ctx.Done():
                    return
                }
            }
            
            // Reorder items within window
            if c.config.ReorderWindow > 0 {
                reorderBuffer = append(reorderBuffer, item)
                
                if len(reorderBuffer) >= c.config.ReorderWindow {
                    // Shuffle buffer
                    for i := range reorderBuffer {
                        j := c.rng.Intn(len(reorderBuffer))
                        reorderBuffer[i], reorderBuffer[j] = reorderBuffer[j], reorderBuffer[i]
                    }
                    
                    // Output shuffled items
                    for _, bufferedItem := range reorderBuffer {
                        select {
                        case out <- bufferedItem:
                        case <-ctx.Done():
                            return
                        }
                    }
                    reorderBuffer = reorderBuffer[:0]
                    atomic.AddInt64(&c.stats.ReorderedItems, int64(c.config.ReorderWindow))
                }
            } else {
                // Direct output
                select {
                case out <- item:
                case <-ctx.Done():
                    return
                }
            }
        }
        
        // Flush remaining reorder buffer
        for _, item := range reorderBuffer {
            select {
            case out <- item:
            case <-ctx.Done():
                return
            }
        }
    }()
    
    return out
}

func (c *ChaosProcessor[T]) Name() string {
    return c.name
}

func (c *ChaosProcessor[T]) GetStats() ChaosStats {
    return ChaosStats{
        TotalItems:      atomic.LoadInt64(&c.stats.TotalItems),
        DroppedItems:    atomic.LoadInt64(&c.stats.DroppedItems),
        DelayedItems:    atomic.LoadInt64(&c.stats.DelayedItems),
        DuplicatedItems: atomic.LoadInt64(&c.stats.DuplicatedItems),
        ReorderedItems:  atomic.LoadInt64(&c.stats.ReorderedItems),
    }
}
```

### 1.3 Integration Test Framework

**Problem:** streamz has minimal integration testing capabilities.

**Solution:** Create comprehensive integration test patterns.

#### Implementation Blueprint:

**File:** `streamz/testing/integration/pipeline_testing.go`
```go
package integration

import (
    "context"
    "testing"
    "time"
    
    "github.com/zoobzio/streamz"
)

// PipelineTestSuite provides comprehensive pipeline testing
type PipelineTestSuite[In, Out any] struct {
    t          *testing.T
    ctx        context.Context
    pipeline   []streamz.Processor[any, any]
    name       string
    timeout    time.Duration
}

func NewPipelineTestSuite[In, Out any](t *testing.T, name string) *PipelineTestSuite[In, Out] {
    return &PipelineTestSuite[In, Out]{
        t:       t,
        ctx:     context.Background(),
        name:    name,
        timeout: 10 * time.Second,
    }
}

func (pts *PipelineTestSuite[In, Out]) WithTimeout(timeout time.Duration) *PipelineTestSuite[In, Out] {
    pts.timeout = timeout
    return pts
}

func (pts *PipelineTestSuite[In, Out]) WithContext(ctx context.Context) *PipelineTestSuite[In, Out] {
    pts.ctx = ctx
    return pts
}

// Test pipeline with expected input/output pairs
func (pts *PipelineTestSuite[In, Out]) TestCases(testCases []TestCase[In, Out]) {
    pts.t.Helper()
    
    for i, tc := range testCases {
        pts.t.Run(tc.Name, func(t *testing.T) {
            input := make(chan In, len(tc.Input))
            for _, item := range tc.Input {
                input <- item
            }
            close(input)
            
            // Create pipeline (would need proper type handling)
            var output <-chan Out
            
            // Collect results with timeout
            ctx, cancel := context.WithTimeout(pts.ctx, pts.timeout)
            defer cancel()
            
            var results []Out
            for {
                select {
                case result, ok := <-output:
                    if !ok {
                        goto compare
                    }
                    results = append(results, result)
                case <-ctx.Done():
                    t.Fatalf("test case %d timeout after %v", i, pts.timeout)
                }
            }
            
        compare:
            if len(results) != len(tc.Expected) {
                t.Errorf("test case %d: expected %d results, got %d", 
                    i, len(tc.Expected), len(results))
                return
            }
            
            // Compare results (would need proper comparison logic)
        })
    }
}

type TestCase[In, Out any] struct {
    Name     string
    Input    []In
    Expected []Out
}

// Error scenario testing
func (pts *PipelineTestSuite[In, Out]) TestErrorPropagation(errorInducers []ErrorInducer[In]) {
    // Test how errors flow through pipeline
}

// Performance testing
func (pts *PipelineTestSuite[In, Out]) TestThroughput(inputSize int, expectedThroughput float64) {
    // Measure pipeline throughput
}

// Backpressure testing
func (pts *PipelineTestSuite[In, Out]) TestBackpressure(slowConsumer bool) {
    // Test pipeline behavior under backpressure
}

type ErrorInducer[In any] struct {
    AtItem   int
    ErrorMsg string
}
```

---

## Priority 2: Error Handling Architecture (URGENT)

### 2.1 Unified Stream Error Type

**Problem:** streamz has inconsistent error handling across processors.

**Solution:** Implement unified error type and handling patterns.

#### Implementation Blueprint:

**File:** `streamz/errors.go`
```go
package streamz

import (
    "context"
    "time"
)

// StreamError provides rich context for stream processing failures
type StreamError[T any] struct {
    ProcessorName string              // Which processor failed
    InputData     T                   // Data that caused the failure
    Err          error                // Underlying error
    Timestamp    time.Time            // When the failure occurred
    Path         []string             // Processing path to failure
    Context      map[string]interface{} // Additional context
}

func (se *StreamError[T]) Error() string {
    if se == nil {
        return "<nil>"
    }
    
    pathStr := ""
    if len(se.Path) > 0 {
        pathStr = " (path: " + strings.Join(se.Path, " â†’ ") + ")"
    }
    
    return fmt.Sprintf("stream processing failed at %s%s: %v", 
        se.ProcessorName, pathStr, se.Err)
}

func (se *StreamError[T]) Unwrap() error {
    if se == nil {
        return nil
    }
    return se.Err
}

// ErrorHandler defines how to handle stream errors
type ErrorHandler[T any] interface {
    HandleError(ctx context.Context, err *StreamError[T]) error
}

// ErrorHandlerFunc adapter
type ErrorHandlerFunc[T any] func(ctx context.Context, err *StreamError[T]) error

func (f ErrorHandlerFunc[T]) HandleError(ctx context.Context, err *StreamError[T]) error {
    return f(ctx, err)
}

// Built-in error handlers
func LogErrorHandler[T any]() ErrorHandler[T] {
    return ErrorHandlerFunc[T](func(ctx context.Context, err *StreamError[T]) error {
        log.Printf("Stream error: %v", err)
        return nil
    })
}

func PanicErrorHandler[T any]() ErrorHandler[T] {
    return ErrorHandlerFunc[T](func(ctx context.Context, err *StreamError[T]) error {
        panic(err)
    })
}

// Error wrapping utilities
func WrapStreamError[T any](processorName string, inputData T, err error, path []string) *StreamError[T] {
    return &StreamError[T]{
        ProcessorName: processorName,
        InputData:     inputData,
        Err:          err,
        Timestamp:    time.Now(),
        Path:         append([]string{}, path...),
        Context:      make(map[string]interface{}),
    }
}
```

### 2.2 Error-Aware Processors

**Problem:** Current processors silently drop errors or handle them inconsistently.

**Solution:** Implement error-aware processor wrapper.

#### Implementation Blueprint:

**File:** `streamz/error_processor.go`
```go
package streamz

import (
    "context"
)

// ErrorAwareProcessor wraps any processor with error handling
type ErrorAwareProcessor[In, Out any] struct {
    name         string
    processor    Processor[In, Out]
    errorHandler ErrorHandler[In]
    skipOnError  bool
}

func NewErrorAwareProcessor[In, Out any](
    name string, 
    processor Processor[In, Out],
    errorHandler ErrorHandler[In],
) *ErrorAwareProcessor[In, Out] {
    return &ErrorAwareProcessor[In, Out]{
        name:         name,
        processor:    processor,
        errorHandler: errorHandler,
        skipOnError:  true, // Default: skip items that cause errors
    }
}

func (eap *ErrorAwareProcessor[In, Out]) WithFailOnError() *ErrorAwareProcessor[In, Out] {
    eap.skipOnError = false
    return eap
}

func (eap *ErrorAwareProcessor[In, Out]) Process(ctx context.Context, in <-chan In) <-chan Out {
    out := make(chan Out)
    
    go func() {
        defer close(out)
        
        // Process through wrapped processor
        processed := eap.processor.Process(ctx, in)
        
        for result := range processed {
            select {
            case out <- result:
            case <-ctx.Done():
                return
            }
        }
    }()
    
    return out
}

func (eap *ErrorAwareProcessor[In, Out]) Name() string {
    return eap.name
}

// For processors that can fail, create error-reporting wrapper
type FallibleProcessor[In, Out any] struct {
    name string
    fn   func(context.Context, In) (Out, error)
    errorHandler ErrorHandler[In]
    path []string
}

func NewFallibleProcessor[In, Out any](
    name string,
    fn func(context.Context, In) (Out, error),
    errorHandler ErrorHandler[In],
) *FallibleProcessor[In, Out] {
    return &FallibleProcessor[In, Out]{
        name:         name,
        fn:           fn,
        errorHandler: errorHandler,
        path:         []string{name},
    }
}

func (fp *FallibleProcessor[In, Out]) Process(ctx context.Context, in <-chan In) <-chan Out {
    out := make(chan Out)
    
    go func() {
        defer close(out)
        
        for item := range in {
            result, err := fp.fn(ctx, item)
            
            if err != nil {
                // Handle error
                streamErr := WrapStreamError(fp.name, item, err, fp.path)
                
                if fp.errorHandler != nil {
                    if handleErr := fp.errorHandler.HandleError(ctx, streamErr); handleErr != nil {
                        // Error handler failed, stop processing
                        return
                    }
                }
                
                // Skip this item (don't send to output)
                continue
            }
            
            // Send successful result
            select {
            case out <- result:
            case <-ctx.Done():
                return
            }
        }
    }()
    
    return out
}

func (fp *FallibleProcessor[In, Out]) Name() string {
    return fp.name
}

func (fp *FallibleProcessor[In, Out]) WithPath(path []string) *FallibleProcessor[In, Out] {
    fp.path = append([]string{}, path...)
    return fp
}
```

---

## Priority 3: Performance Benchmarking (HIGH)

### 3.1 Comprehensive Benchmark Suite

**Problem:** streamz lacks performance benchmarks for regression detection.

**Solution:** Implement comprehensive benchmarking following pipz patterns.

#### Implementation Blueprint:

**File:** `streamz/testing/benchmarks/comprehensive_test.go`
```go
package benchmarks

import (
    "context"
    "testing"
    "time"
    
    "github.com/zoobzio/streamz"
    "github.com/zoobzio/streamz/testing/helpers"
)

// BenchmarkProcessorPerformance benchmarks individual processor types
func BenchmarkProcessorPerformance(b *testing.B) {
    ctx := context.Background()
    
    b.Run("Mapper_SingleItem", func(b *testing.B) {
        mapper := streamz.NewMapper(func(n int) int { return n * 2 })
        
        b.ResetTimer()
        b.ReportAllocs()
        
        for i := 0; i < b.N; i++ {
            input := make(chan int, 1)
            input <- i
            close(input)
            
            output := mapper.Process(ctx, input)
            <-output // Consume result
        }
    })
    
    b.Run("Filter_SingleItem", func(b *testing.B) {
        filter := streamz.NewFilter(func(n int) bool { return n%2 == 0 })
        
        b.ResetTimer()
        b.ReportAllocs()
        
        for i := 0; i < b.N; i++ {
            input := make(chan int, 1)
            input <- i
            close(input)
            
            output := filter.Process(ctx, input)
            helpers.DrainChannel(output)
        }
    })
    
    b.Run("AsyncMapper_Throughput", func(b *testing.B) {
        mapper := streamz.NewAsyncMapper(func(_ context.Context, n int) (int, error) {
            return n * 2, nil
        }).WithWorkers(4)
        
        b.ResetTimer()
        b.ReportAllocs()
        
        input := make(chan int, b.N)
        output := mapper.Process(ctx, input)
        
        // Start consumer
        done := make(chan bool)
        go func() {
            helpers.DrainChannel(output)
            done <- true
        }()
        
        // Produce items
        for i := 0; i < b.N; i++ {
            input <- i
        }
        close(input)
        <-done
    })
    
    b.Run("CircuitBreaker_Closed", func(b *testing.B) {
        processor := streamz.NewMapper(func(n int) int { return n * 2 })
        breaker := streamz.NewCircuitBreaker(processor, streamz.RealClock).
            FailureThreshold(0.5).
            MinRequests(100)
        
        b.ResetTimer()
        b.ReportAllocs()
        
        for i := 0; i < b.N; i++ {
            input := make(chan int, 1)
            input <- i
            close(input)
            
            output := breaker.Process(ctx, input)
            helpers.DrainChannel(output)
        }
    })
}

// BenchmarkMemoryAllocation measures memory allocation patterns
func BenchmarkMemoryAllocation(b *testing.B) {
    ctx := context.Background()
    
    b.Run("Zero_Alloc_Transform", func(b *testing.B) {
        // Test if simple transforms can be zero-alloc
        mapper := streamz.NewMapper(func(n int) int { return n * 2 })
        
        b.ResetTimer()
        b.ReportAllocs()
        
        for i := 0; i < b.N; i++ {
            input := make(chan int, 1)
            input <- 42
            close(input)
            
            output := mapper.Process(ctx, input)
            <-output
        }
    })
    
    b.Run("Channel_Overhead", func(b *testing.B) {
        b.ResetTimer()
        b.ReportAllocs()
        
        for i := 0; i < b.N; i++ {
            input := make(chan int, 1)
            output := make(chan int, 1)
            
            go func() {
                for item := range input {
                    output <- item * 2
                }
                close(output)
            }()
            
            input <- 42
            close(input)
            <-output
        }
    })
}

// BenchmarkConcurrentThroughput measures throughput under concurrent load
func BenchmarkConcurrentThroughput(b *testing.B) {
    ctx := context.Background()
    
    workerCounts := []int{1, 2, 4, 8, 16}
    
    for _, workers := range workerCounts {
        b.Run(fmt.Sprintf("workers-%d", workers), func(b *testing.B) {
            mapper := streamz.NewAsyncMapper(func(_ context.Context, n int) (int, error) {
                // Simulate work
                time.Sleep(100 * time.Microsecond)
                return n * 2, nil
            }).WithWorkers(workers)
            
            input := make(chan int, b.N)
            output := mapper.Process(ctx, input)
            
            // Consumer
            done := make(chan bool)
            go func() {
                count := 0
                for range output {
                    count++
                }
                done <- true
            }()
            
            b.ResetTimer()
            
            // Producer
            for i := 0; i < b.N; i++ {
                input <- i
            }
            close(input)
            <-done
        })
    }
}

// BenchmarkPipelineComposition measures pipeline performance
func BenchmarkPipelineComposition(b *testing.B) {
    ctx := context.Background()
    
    b.Run("Short_Pipeline", func(b *testing.B) {
        // 3-stage pipeline
        filter := streamz.NewFilter(func(n int) bool { return n > 0 })
        mapper := streamz.NewMapper(func(n int) int { return n * 2 })
        batcher := streamz.NewBatcher[int](streamz.BatchConfig{MaxSize: 10}, streamz.RealClock)
        
        b.ResetTimer()
        b.ReportAllocs()
        
        for i := 0; i < b.N; i++ {
            input := make(chan int, 1)
            input <- i
            close(input)
            
            // Chain processors
            filtered := filter.Process(ctx, input)
            mapped := mapper.Process(ctx, filtered)
            batched := batcher.Process(ctx, mapped)
            
            helpers.DrainChannel(batched)
        }
    })
    
    b.Run("Long_Pipeline", func(b *testing.B) {
        // 10-stage pipeline
        processors := make([]streamz.Processor[int, int], 10)
        for i := 0; i < 10; i++ {
            processors[i] = streamz.NewMapper(func(n int) int { return n + 1 })
        }
        
        b.ResetTimer()
        b.ReportAllocs()
        
        for i := 0; i < b.N; i++ {
            input := make(chan int, 1)
            input <- i
            close(input)
            
            // Chain all processors
            current := input
            for _, proc := range processors {
                current = proc.Process(ctx, current)
            }
            
            helpers.DrainChannel(current)
        }
    })
}
```

### 3.2 Performance Comparison Framework

**Problem:** Need to compare streamz performance against pipz and other libraries.

**Solution:** Create comparative benchmarking framework.

#### Implementation Blueprint:

**File:** `streamz/testing/benchmarks/comparison_test.go`
```go
package benchmarks

import (
    "context"
    "testing"
    
    "github.com/zoobzio/streamz"
    "github.com/zoobzio/pipz"
)

// BenchmarkStreamzVsPipz compares equivalent operations
func BenchmarkStreamzVsPipz(b *testing.B) {
    ctx := context.Background()
    
    b.Run("SimpleTransform", func(b *testing.B) {
        b.Run("streamz", func(b *testing.B) {
            mapper := streamz.NewMapper(func(n int) int { return n * 2 })
            
            b.ResetTimer()
            b.ReportAllocs()
            
            for i := 0; i < b.N; i++ {
                input := make(chan int, 1)
                input <- i
                close(input)
                
                output := mapper.Process(ctx, input)
                <-output
            }
        })
        
        b.Run("pipz", func(b *testing.B) {
            processor := pipz.Transform("double", func(_ context.Context, n int) int {
                return n * 2
            })
            
            b.ResetTimer()
            b.ReportAllocs()
            
            for i := 0; i < b.N; i++ {
                result, err := processor.Process(ctx, i)
                if err != nil {
                    b.Fatal(err)
                }
                _ = result
            }
        })
    })
    
    b.Run("ErrorHandling", func(b *testing.B) {
        b.Run("streamz", func(b *testing.B) {
            mapper := streamz.NewAsyncMapper(func(_ context.Context, n int) (int, error) {
                if n%10 == 0 {
                    return 0, errors.New("divisible by 10")
                }
                return n * 2, nil
            })
            
            b.ResetTimer()
            b.ReportAllocs()
            
            for i := 0; i < b.N; i++ {
                input := make(chan int, 1)
                input <- i
                close(input)
                
                output := mapper.Process(ctx, input)
                for range output { } // Drain
            }
        })
        
        b.Run("pipz", func(b *testing.B) {
            processor := pipz.Apply("maybe-fail", func(_ context.Context, n int) (int, error) {
                if n%10 == 0 {
                    return 0, errors.New("divisible by 10")
                }
                return n * 2, nil
            })
            
            b.ResetTimer()
            b.ReportAllocs()
            
            for i := 0; i < b.N; i++ {
                result, err := processor.Process(ctx, i)
                _ = result
                _ = err
            }
        })
    })
}

// BenchmarkMemoryUsageComparison compares memory usage patterns
func BenchmarkMemoryUsageComparison(b *testing.B) {
    // Compare memory allocation patterns between streamz and pipz
}
```

---

## Priority 4: Integration Adapters (MEDIUM)

### 4.1 Bidirectional Adapters

**Problem:** Cannot easily combine pipz and streamz processors in the same pipeline.

**Solution:** Create adapter patterns for seamless interoperability.

#### Implementation Blueprint:

**File:** `streamz/interop/adapters.go`
```go
package interop

import (
    "context"
    
    "github.com/zoobzio/pipz"
    "github.com/zoobzio/streamz"
)

// PipzToStreamz converts a pipz processor to streamz processor
func PipzToStreamz[T any](processor pipz.Chainable[T]) streamz.Processor[T, T] {
    return &pipzAdapter[T]{
        processor: processor,
        name:      processor.Name(),
    }
}

type pipzAdapter[T any] struct {
    processor pipz.Chainable[T]
    name      string
}

func (pa *pipzAdapter[T]) Process(ctx context.Context, in <-chan T) <-chan T {
    out := make(chan T)
    
    go func() {
        defer close(out)
        
        for item := range in {
            result, err := pa.processor.Process(ctx, item)
            if err != nil {
                // Convert pipz error to streamz behavior (skip item)
                // Could also be configurable
                continue
            }
            
            select {
            case out <- result:
            case <-ctx.Done():
                return
            }
        }
    }()
    
    return out
}

func (pa *pipzAdapter[T]) Name() string {
    return pa.name
}

// StreamzToPipz converts a streamz processor to pipz processor
func StreamzToPipz[T any](processor streamz.Processor[T, T]) pipz.Chainable[T] {
    return &streamzAdapter[T]{
        processor: processor,
        name:      processor.Name(),
    }
}

type streamzAdapter[T any] struct {
    processor streamz.Processor[T, T]
    name      string
}

func (sa *streamzAdapter[T]) Process(ctx context.Context, data T) (T, error) {
    // Create single-item channel
    input := make(chan T, 1)
    input <- data
    close(input)
    
    // Process through streamz processor
    output := sa.processor.Process(ctx, input)
    
    // Wait for result or timeout
    select {
    case result, ok := <-output:
        if !ok {
            // Channel closed without result (likely error)
            var zero T
            return zero, errors.New("streamz processor failed")
        }
        return result, nil
        
    case <-time.After(10 * time.Second): // Configurable timeout
        var zero T
        return zero, errors.New("streamz processor timeout")
        
    case <-ctx.Done():
        var zero T
        return zero, ctx.Err()
    }
}

func (sa *streamzAdapter[T]) Name() pipz.Name {
    return pipz.Name(sa.name)
}

// Hybrid processors that support both interfaces
type HybridProcessor[T any] struct {
    name      string
    singleFn  func(context.Context, T) (T, error)
    streamFn  func(context.Context, <-chan T) <-chan T
}

func NewHybridProcessor[T any](
    name string,
    singleFn func(context.Context, T) (T, error),
) *HybridProcessor[T] {
    hp := &HybridProcessor[T]{
        name:     name,
        singleFn: singleFn,
    }
    
    // Generate stream function from single function
    hp.streamFn = func(ctx context.Context, in <-chan T) <-chan T {
        out := make(chan T)
        
        go func() {
            defer close(out)
            
            for item := range in {
                result, err := singleFn(ctx, item)
                if err != nil {
                    // Skip item on error (configurable)
                    continue
                }
                
                select {
                case out <- result:
                case <-ctx.Done():
                    return
                }
            }
        }()
        
        return out
    }
    
    return hp
}

// Implement pipz.Chainable
func (hp *HybridProcessor[T]) Process(ctx context.Context, data T) (T, error) {
    return hp.singleFn(ctx, data)
}

// Implement streamz.Processor
func (hp *HybridProcessor[T]) ProcessStream(ctx context.Context, in <-chan T) <-chan T {
    return hp.streamFn(ctx, in)
}

func (hp *HybridProcessor[T]) Name() string {
    return hp.name
}

// Convenience constructors
func HybridMapper[In, Out any](name string, fn func(In) Out) *HybridProcessor[In] {
    return NewHybridProcessor(name, func(_ context.Context, data In) (In, error) {
        // Note: This is a simplified example - real implementation would need
        // to handle In != Out case properly
        result := fn(data)
        return any(result).(In), nil // Unsafe cast for example
    })
}
```

---

## Implementation Roadmap

### Phase 1: Critical Foundation (Week 1-2)
1. **Mock Processor Framework** - Enable proper unit testing
2. **Basic Error Handling** - StreamError type and basic handlers
3. **Simple Benchmarks** - Performance baseline establishment

### Phase 2: Testing Infrastructure (Week 3-4)  
1. **Chaos Engineering** - Reliability testing capabilities
2. **Integration Test Framework** - End-to-end pipeline testing
3. **Comprehensive Benchmarks** - Memory, throughput, comparison tests

### Phase 3: Production Readiness (Week 5-6)
1. **Error-Aware Processors** - Unified error handling
2. **Performance Optimization** - Address benchmark findings
3. **Documentation Updates** - Match pipz documentation quality

### Phase 4: Integration (Week 7-8)
1. **Bidirectional Adapters** - pipz/streamz interoperability  
2. **Hybrid Processors** - Support both processing models
3. **Migration Utilities** - Help transition between architectures

---

## Success Metrics

### Testing Infrastructure Success
- [ ] Mock processors support all testing scenarios
- [ ] Chaos testing finds real reliability issues  
- [ ] Integration tests cover all common patterns
- [ ] Test coverage >90% across core processors

### Error Handling Success  
- [ ] All errors provide rich debugging context
- [ ] Error handling is consistent across processors
- [ ] Error scenarios are well-tested
- [ ] Production debugging is straightforward

### Performance Success
- [ ] Benchmarks establish clear baselines
- [ ] Performance regressions are caught early
- [ ] Memory allocation is predictable
- [ ] Throughput matches expectations

### Integration Success
- [ ] pipz processors work in streamz pipelines
- [ ] streamz processors work in pipz sequences  
- [ ] Performance overhead is minimal
- [ ] Error handling works across boundaries

---

## Conclusion

These recommendations provide a **concrete path** to bring streamz up to production standards. The testing infrastructure improvements are critical and should be implemented immediately. 

The key insight is that **pipz's success comes from its mature engineering practices**, not just its architecture. streamz needs to adopt these same practices to be viable for production use.

**Next steps:**
1. Implement Priority 1 (Testing) immediately
2. Add Priority 2 (Error Handling) in parallel  
3. Establish benchmarks to track progress
4. Build integration capabilities for interoperability

This implementation plan addresses the critical gaps identified in the technical analysis and provides a roadmap to production readiness.